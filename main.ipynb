{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[---Saved Object---]\n",
      "0 : Ball\n",
      "1 : Bottle\n",
      "2 : Buds2\n",
      "3 : Daffa\n",
      "4 : Hand\n",
      "5 : L\n",
      "6 : Mouse\n",
      "7 : Pen\n",
      "8 : Phone\n"
     ]
    }
   ],
   "source": [
    "from vidcam import VideoCapture\n",
    "import os\n",
    "from preprocessing import object_preprocessing as op\n",
    "from neural_network import neural_network_engine as nne\n",
    "\n",
    "frame_data = r'D:/Kuliah Telkom University/Python/TCM/Learn/Neural Network/Interactive Test/frame_data'\n",
    "default_path = r'D:/Kuliah Telkom University/Python/TCM/Learn/Neural Network/Interactive Test'\n",
    "\n",
    "while(True):\n",
    "    flag = input(\"Add new object?(Yes/No) \")\n",
    "    if(flag.lower() == \"no\"):\n",
    "        break\n",
    "    while(flag.lower() != \"yes\"):\n",
    "        flag = input(\"Add new object?(Yes/No) \")\n",
    "\n",
    "    object_name = input(\"Input your object name : \")\n",
    "    VideoCapture.record(object_name, default_path)\n",
    "    count_frame = VideoCapture.vid2frame(object_name, default_path)\n",
    "\n",
    "    if count_frame < 300:\n",
    "        print(f\"Not enough frame data to process!!! Frame Count : {count_frame} Needed : 300\")\n",
    "        VideoCapture.abandon(object_name, default_path)\n",
    "    else:\n",
    "        print(f\"{object_name} has been created!!!\")\n",
    "\n",
    "frame_data = r'D:/Kuliah Telkom University/Python/TCM/Learn/Neural Network/Interactive Test/frame_data'\n",
    "default_path = r'D:/Kuliah Telkom University/Python/TCM/Learn/Neural Network/Interactive Test'\n",
    "available_object = os.listdir(frame_data)\n",
    "print(\"\\n[---Saved Object---]\")\n",
    "for i in range(len(available_object)):\n",
    "    print(f\"{i} : {available_object[i].capitalize()}\")\n",
    "\n",
    "class_len = len(available_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load split data\n",
      "Load Excel Success\n",
      "Preparing the data\n"
     ]
    }
   ],
   "source": [
    "img_height_resize = 120\n",
    "img_weight_resize = 120\n",
    "\n",
    "pre_data = op(frame_data, default_path)\n",
    "mode = int(input(\"\\nWhich one do you prefer?\\n1. Use new data\\n2. Load existing data\\nChoose : \"))\n",
    "if(mode==1):\n",
    "    pre_data.split_data(available_object)\n",
    "else:\n",
    "    pre_data.load_excel_split()\n",
    "\n",
    "pre_data.prepare_data(img_height_resize, img_weight_resize, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DA4\\anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "88/88 [==============================] - 5s 19ms/step - loss: 1.3316 - accuracy: 0.5476 - val_loss: 0.6043 - val_accuracy: 0.7226\n",
      "Epoch 2/10\n",
      "88/88 [==============================] - 1s 16ms/step - loss: 0.4711 - accuracy: 0.8507 - val_loss: 0.2237 - val_accuracy: 0.9252\n",
      "Epoch 3/10\n",
      "88/88 [==============================] - 1s 16ms/step - loss: 0.2068 - accuracy: 0.9441 - val_loss: 0.0945 - val_accuracy: 0.9684\n",
      "Epoch 4/10\n",
      "88/88 [==============================] - 1s 16ms/step - loss: 0.1286 - accuracy: 0.9694 - val_loss: 0.0603 - val_accuracy: 0.9801\n",
      "Epoch 5/10\n",
      "88/88 [==============================] - 1s 16ms/step - loss: 0.0948 - accuracy: 0.9743 - val_loss: 0.0510 - val_accuracy: 0.9801\n",
      "Epoch 6/10\n",
      "88/88 [==============================] - 1s 16ms/step - loss: 0.0872 - accuracy: 0.9726 - val_loss: 0.0333 - val_accuracy: 0.9950\n",
      "Epoch 7/10\n",
      "88/88 [==============================] - 1s 16ms/step - loss: 0.0533 - accuracy: 0.9865 - val_loss: 0.0351 - val_accuracy: 0.9934\n",
      "Epoch 8/10\n",
      "88/88 [==============================] - 1s 16ms/step - loss: 0.0489 - accuracy: 0.9865 - val_loss: 0.1060 - val_accuracy: 0.9618\n",
      "Epoch 9/10\n",
      "88/88 [==============================] - 1s 16ms/step - loss: 0.0478 - accuracy: 0.9857 - val_loss: 0.0255 - val_accuracy: 0.9884\n",
      "Epoch 10/10\n",
      "88/88 [==============================] - 1s 16ms/step - loss: 0.0477 - accuracy: 0.9890 - val_loss: 0.0165 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "gas = nne()\n",
    "gas.build_layer(class_len, img_height_resize, img_weight_resize, default_path)\n",
    "gas.train(pre_data.x_train, pre_data.y_train, pre_data.x_val, pre_data.y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 120, 120, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 60, 60, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 115200)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               58982912  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 4617      \n",
      "=================================================================\n",
      "Total params: 58,988,425\n",
      "Trainable params: 58,988,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "gas.model_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0179 - accuracy: 1.0000\n",
      "Test Loss : 0.017920125275850296 | Test Accuracy : 100.0%\n"
     ]
    }
   ],
   "source": [
    "gas.model_evaluation(pre_data.x_test, pre_data.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        70\n",
      "           1       1.00      1.00      1.00        64\n",
      "           2       1.00      1.00      1.00        71\n",
      "           3       1.00      1.00      1.00        65\n",
      "           4       1.00      1.00      1.00        68\n",
      "           5       1.00      1.00      1.00        33\n",
      "           6       1.00      1.00      1.00        68\n",
      "           7       1.00      1.00      1.00        73\n",
      "           8       1.00      1.00      1.00        94\n",
      "\n",
      "    accuracy                           1.00       606\n",
      "   macro avg       1.00      1.00      1.00       606\n",
      "weighted avg       1.00      1.00      1.00       606\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gas.confusion_matrix(pre_data.x_test, pre_data.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at : D:/Kuliah Telkom University/Python/TCM/Learn/Neural Network/Interactive Test/saved_model/Yahaha_9.h5\n"
     ]
    }
   ],
   "source": [
    "gas.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the data\n",
      "[Prediction Result]\n",
      "20220504_105533.jpg => hand\n"
     ]
    }
   ],
   "source": [
    "pre_data.prepare_data(img_height_resize, img_weight_resize, flag='predict')\n",
    "\n",
    "prediction_data, prediction_datalist = pre_data.predict_data, pre_data.predict_file_list\n",
    "\n",
    "gas.prediction(prediction_data, prediction_datalist, available_object)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tensor-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "069fac32164d4f8826d0272ba60b2aaaccb33d3d979105e0660a65963367c925"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
