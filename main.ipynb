{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[---Saved Object---]\n",
      "0 : Abdul\n",
      "1 : Ayaka\n",
      "2 : Ball\n",
      "3 : Bottle\n",
      "4 : Buds2\n",
      "5 : Da4\n",
      "6 : Daffa\n",
      "7 : Hand\n",
      "8 : Kazuha\n",
      "9 : Keqing\n",
      "10 : Mouse\n",
      "11 : Pen\n",
      "12 : Phone\n",
      "13 : Xiao\n"
     ]
    }
   ],
   "source": [
    "from vidcam import VideoCapture\n",
    "import os\n",
    "from preprocessing import object_preprocessing as op\n",
    "from neural_network import neural_network_engine as nne\n",
    "import pathlib\n",
    "\n",
    "frame_data = f'{pathlib.Path().resolve()}/frame_data'\n",
    "default_path = f'{pathlib.Path().resolve()}'\n",
    "\n",
    "while(True):\n",
    "    flag = input(\"Add new object?(Yes/No) \")\n",
    "    if(flag.lower() == \"no\"):\n",
    "        break\n",
    "    while(flag.lower() != \"yes\"):\n",
    "        flag = input(\"Add new object?(Yes/No) \")\n",
    "\n",
    "    object_name = input(\"Input your object name : \")\n",
    "    VideoCapture.record(object_name, default_path)\n",
    "    count_frame = VideoCapture.vid2frame(object_name, default_path)\n",
    "\n",
    "    if count_frame < 300:\n",
    "        print(f\"Not enough frame data to process!!! Frame Count : {count_frame} Needed : 300\")\n",
    "        VideoCapture.abandon(object_name, default_path)\n",
    "    else:\n",
    "        print(f\"{object_name} has been created!!!\")\n",
    "\n",
    "available_object = os.listdir(frame_data)\n",
    "print(\"\\n[---Saved Object---]\")\n",
    "for i in range(len(available_object)):\n",
    "    print(f\"{i} : {available_object[i].capitalize()}\")\n",
    "\n",
    "class_len = len(available_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting the data\n",
      "D:\\Kuliah Telkom University\\Python\\TCM\\Learn\\Neural Network\\Interactive Test/frame_data/abdul\n",
      "---------------------------------\n",
      "Object Name :  abdul\n",
      "Object Code :  0\n",
      "Total Images:  615\n",
      "Training :  430\n",
      "Validation :  92\n",
      "Testing :  93\n",
      "D:\\Kuliah Telkom University\\Python\\TCM\\Learn\\Neural Network\\Interactive Test/frame_data/ayaka\n",
      "---------------------------------\n",
      "Object Name :  ayaka\n",
      "Object Code :  1\n",
      "Total Images:  161\n",
      "Training :  112\n",
      "Validation :  24\n",
      "Testing :  25\n",
      "D:\\Kuliah Telkom University\\Python\\TCM\\Learn\\Neural Network\\Interactive Test/frame_data/ball\n",
      "---------------------------------\n",
      "Object Name :  ball\n",
      "Object Code :  2\n",
      "Total Images:  461\n",
      "Training :  322\n",
      "Validation :  69\n",
      "Testing :  70\n",
      "D:\\Kuliah Telkom University\\Python\\TCM\\Learn\\Neural Network\\Interactive Test/frame_data/bottle\n",
      "---------------------------------\n",
      "Object Name :  bottle\n",
      "Object Code :  3\n",
      "Total Images:  425\n",
      "Training :  297\n",
      "Validation :  64\n",
      "Testing :  64\n",
      "D:\\Kuliah Telkom University\\Python\\TCM\\Learn\\Neural Network\\Interactive Test/frame_data/buds2\n",
      "---------------------------------\n",
      "Object Name :  buds2\n",
      "Object Code :  4\n",
      "Total Images:  471\n",
      "Training :  329\n",
      "Validation :  71\n",
      "Testing :  71\n",
      "D:\\Kuliah Telkom University\\Python\\TCM\\Learn\\Neural Network\\Interactive Test/frame_data/da4\n",
      "---------------------------------\n",
      "Object Name :  da4\n",
      "Object Code :  5\n",
      "Total Images:  513\n",
      "Training :  359\n",
      "Validation :  77\n",
      "Testing :  77\n",
      "D:\\Kuliah Telkom University\\Python\\TCM\\Learn\\Neural Network\\Interactive Test/frame_data/daffa\n",
      "---------------------------------\n",
      "Object Name :  daffa\n",
      "Object Code :  6\n",
      "Total Images:  513\n",
      "Training :  359\n",
      "Validation :  77\n",
      "Testing :  77\n",
      "D:\\Kuliah Telkom University\\Python\\TCM\\Learn\\Neural Network\\Interactive Test/frame_data/hand\n",
      "---------------------------------\n",
      "Object Name :  hand\n",
      "Object Code :  7\n",
      "Total Images:  452\n",
      "Training :  316\n",
      "Validation :  68\n",
      "Testing :  68\n",
      "D:\\Kuliah Telkom University\\Python\\TCM\\Learn\\Neural Network\\Interactive Test/frame_data/kazuha\n",
      "---------------------------------\n",
      "Object Name :  kazuha\n",
      "Object Code :  8\n",
      "Total Images:  171\n",
      "Training :  119\n",
      "Validation :  26\n",
      "Testing :  26\n",
      "D:\\Kuliah Telkom University\\Python\\TCM\\Learn\\Neural Network\\Interactive Test/frame_data/keqing\n",
      "---------------------------------\n",
      "Object Name :  keqing\n",
      "Object Code :  9\n",
      "Total Images:  211\n",
      "Training :  147\n",
      "Validation :  32\n",
      "Testing :  32\n",
      "D:\\Kuliah Telkom University\\Python\\TCM\\Learn\\Neural Network\\Interactive Test/frame_data/mouse\n",
      "---------------------------------\n",
      "Object Name :  mouse\n",
      "Object Code :  10\n",
      "Total Images:  447\n",
      "Training :  312\n",
      "Validation :  67\n",
      "Testing :  68\n",
      "D:\\Kuliah Telkom University\\Python\\TCM\\Learn\\Neural Network\\Interactive Test/frame_data/pen\n",
      "---------------------------------\n",
      "Object Name :  pen\n",
      "Object Code :  11\n",
      "Total Images:  483\n",
      "Training :  338\n",
      "Validation :  72\n",
      "Testing :  73\n",
      "D:\\Kuliah Telkom University\\Python\\TCM\\Learn\\Neural Network\\Interactive Test/frame_data/phone\n",
      "---------------------------------\n",
      "Object Name :  phone\n",
      "Object Code :  12\n",
      "Total Images:  623\n",
      "Training :  436\n",
      "Validation :  93\n",
      "Testing :  94\n",
      "D:\\Kuliah Telkom University\\Python\\TCM\\Learn\\Neural Network\\Interactive Test/frame_data/xiao\n",
      "---------------------------------\n",
      "Object Name :  xiao\n",
      "Object Code :  13\n",
      "Total Images:  185\n",
      "Training :  129\n",
      "Validation :  28\n",
      "Testing :  28\n",
      "---------------------------------\n",
      "Saving split data\n",
      "Save Excel Success\n",
      "Preparing the data\n"
     ]
    }
   ],
   "source": [
    "img_height_resize = 128\n",
    "img_weight_resize = 128\n",
    "\n",
    "pre_data = op(frame_data, default_path)\n",
    "mode = int(input(\"\\nWhich one do you prefer?\\n1. Use new data\\n2. Load existing data\\nChoose : \"))\n",
    "if(mode==1):\n",
    "    pre_data.split_data(available_object)\n",
    "else:\n",
    "    pre_data.load_excel_split()\n",
    "\n",
    "pre_data.prepare_data(img_height_resize, img_weight_resize, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DA4\\anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "126/126 [==============================] - 6s 20ms/step - loss: 1.7437 - accuracy: 0.4602 - val_loss: 1.8024 - val_accuracy: 0.4605\n",
      "Epoch 2/50\n",
      "126/126 [==============================] - 2s 18ms/step - loss: 0.9231 - accuracy: 0.7069 - val_loss: 0.7894 - val_accuracy: 0.7000\n",
      "Epoch 3/50\n",
      "126/126 [==============================] - 2s 18ms/step - loss: 0.6069 - accuracy: 0.7773 - val_loss: 0.5128 - val_accuracy: 0.7779\n",
      "Epoch 4/50\n",
      "126/126 [==============================] - 2s 18ms/step - loss: 0.4749 - accuracy: 0.8080 - val_loss: 0.6177 - val_accuracy: 0.7860\n",
      "Epoch 5/50\n",
      "126/126 [==============================] - 2s 18ms/step - loss: 0.3996 - accuracy: 0.8340 - val_loss: 0.3776 - val_accuracy: 0.8465\n",
      "Epoch 6/50\n",
      "126/126 [==============================] - 2s 18ms/step - loss: 0.3592 - accuracy: 0.8419 - val_loss: 0.4343 - val_accuracy: 0.8140\n",
      "Epoch 7/50\n",
      "126/126 [==============================] - 2s 18ms/step - loss: 0.3246 - accuracy: 0.8469 - val_loss: 0.3194 - val_accuracy: 0.8430\n",
      "Epoch 8/50\n",
      "126/126 [==============================] - 2s 18ms/step - loss: 0.3045 - accuracy: 0.8522 - val_loss: 0.3023 - val_accuracy: 0.8523\n",
      "Epoch 9/50\n",
      "126/126 [==============================] - 2s 19ms/step - loss: 0.2913 - accuracy: 0.8592 - val_loss: 0.2761 - val_accuracy: 0.8721\n",
      "Epoch 10/50\n",
      "126/126 [==============================] - 2s 19ms/step - loss: 0.2712 - accuracy: 0.8677 - val_loss: 0.3120 - val_accuracy: 0.8500\n",
      "Epoch 11/50\n",
      "126/126 [==============================] - 2s 18ms/step - loss: 0.2557 - accuracy: 0.8679 - val_loss: 0.3241 - val_accuracy: 0.8698\n",
      "Epoch 12/50\n",
      "126/126 [==============================] - 3s 20ms/step - loss: 0.2520 - accuracy: 0.8727 - val_loss: 0.2553 - val_accuracy: 0.8605\n",
      "Epoch 13/50\n",
      "126/126 [==============================] - 2s 19ms/step - loss: 0.2436 - accuracy: 0.8757 - val_loss: 0.2543 - val_accuracy: 0.8709\n",
      "Epoch 14/50\n",
      "126/126 [==============================] - 2s 18ms/step - loss: 0.2372 - accuracy: 0.8764 - val_loss: 0.2620 - val_accuracy: 0.8767\n",
      "Epoch 15/50\n",
      "126/126 [==============================] - 2s 18ms/step - loss: 0.2300 - accuracy: 0.8762 - val_loss: 0.2705 - val_accuracy: 0.8709\n",
      "Epoch 16/50\n",
      "126/126 [==============================] - 2s 18ms/step - loss: 0.2262 - accuracy: 0.8799 - val_loss: 0.2525 - val_accuracy: 0.8744\n",
      "Epoch 17/50\n",
      "126/126 [==============================] - 2s 18ms/step - loss: 0.2181 - accuracy: 0.8772 - val_loss: 0.3123 - val_accuracy: 0.8814\n",
      "Epoch 18/50\n",
      "126/126 [==============================] - 2s 18ms/step - loss: 0.2149 - accuracy: 0.8836 - val_loss: 0.2707 - val_accuracy: 0.8651\n",
      "Epoch 19/50\n",
      "126/126 [==============================] - 2s 18ms/step - loss: 0.2104 - accuracy: 0.8861 - val_loss: 0.2513 - val_accuracy: 0.8860\n",
      "Epoch 20/50\n",
      "126/126 [==============================] - 2s 18ms/step - loss: 0.2047 - accuracy: 0.8891 - val_loss: 0.2440 - val_accuracy: 0.8756\n",
      "Epoch 21/50\n",
      "126/126 [==============================] - 2s 18ms/step - loss: 0.2000 - accuracy: 0.8879 - val_loss: 0.2504 - val_accuracy: 0.8663\n",
      "Epoch 22/50\n",
      "126/126 [==============================] - 2s 19ms/step - loss: 0.1957 - accuracy: 0.8951 - val_loss: 0.2820 - val_accuracy: 0.8814\n",
      "Epoch 23/50\n",
      "126/126 [==============================] - 2s 18ms/step - loss: 0.1995 - accuracy: 0.8909 - val_loss: 0.2605 - val_accuracy: 0.8651\n",
      "Epoch 24/50\n",
      "126/126 [==============================] - 2s 18ms/step - loss: 0.1902 - accuracy: 0.8951 - val_loss: 0.2681 - val_accuracy: 0.8802\n",
      "Epoch 25/50\n",
      "126/126 [==============================] - 2s 19ms/step - loss: 0.1905 - accuracy: 0.8944 - val_loss: 0.2280 - val_accuracy: 0.8837\n",
      "Epoch 26/50\n",
      "126/126 [==============================] - 2s 18ms/step - loss: 0.1833 - accuracy: 0.9014 - val_loss: 0.2637 - val_accuracy: 0.8802\n",
      "Epoch 27/50\n",
      "126/126 [==============================] - 2s 19ms/step - loss: 0.1821 - accuracy: 0.8984 - val_loss: 0.2732 - val_accuracy: 0.8860\n",
      "Epoch 28/50\n",
      "126/126 [==============================] - 3s 20ms/step - loss: 0.1787 - accuracy: 0.8996 - val_loss: 0.2415 - val_accuracy: 0.8756\n",
      "Epoch 29/50\n",
      "126/126 [==============================] - 2s 19ms/step - loss: 0.1779 - accuracy: 0.8976 - val_loss: 0.4631 - val_accuracy: 0.8512\n",
      "Epoch 30/50\n",
      "126/126 [==============================] - 2s 19ms/step - loss: 0.1855 - accuracy: 0.8949 - val_loss: 0.2343 - val_accuracy: 0.8791\n",
      "Epoch 31/50\n",
      "126/126 [==============================] - 3s 21ms/step - loss: 0.1738 - accuracy: 0.8956 - val_loss: 0.2305 - val_accuracy: 0.8779\n",
      "Epoch 32/50\n",
      "126/126 [==============================] - 2s 19ms/step - loss: 0.1694 - accuracy: 0.9019 - val_loss: 0.2251 - val_accuracy: 0.8895\n",
      "Epoch 33/50\n",
      "126/126 [==============================] - 2s 19ms/step - loss: 0.1705 - accuracy: 0.8979 - val_loss: 0.2855 - val_accuracy: 0.8558\n",
      "Epoch 34/50\n",
      "126/126 [==============================] - 2s 19ms/step - loss: 0.1711 - accuracy: 0.8944 - val_loss: 0.2304 - val_accuracy: 0.8802\n",
      "Epoch 35/50\n",
      "126/126 [==============================] - 2s 18ms/step - loss: 0.1697 - accuracy: 0.8971 - val_loss: 0.2359 - val_accuracy: 0.8756\n",
      "Epoch 36/50\n",
      "126/126 [==============================] - 2s 18ms/step - loss: 0.1629 - accuracy: 0.9006 - val_loss: 0.2574 - val_accuracy: 0.8756\n",
      "Epoch 37/50\n",
      "126/126 [==============================] - 2s 19ms/step - loss: 0.1665 - accuracy: 0.8969 - val_loss: 0.3631 - val_accuracy: 0.8512\n",
      "Epoch 38/50\n",
      "126/126 [==============================] - 2s 19ms/step - loss: 0.1697 - accuracy: 0.9011 - val_loss: 0.2279 - val_accuracy: 0.8698\n",
      "Epoch 39/50\n",
      "126/126 [==============================] - 2s 18ms/step - loss: 0.1627 - accuracy: 0.8999 - val_loss: 0.2259 - val_accuracy: 0.8791\n",
      "Epoch 40/50\n",
      "126/126 [==============================] - 2s 19ms/step - loss: 0.1575 - accuracy: 0.9034 - val_loss: 0.2606 - val_accuracy: 0.8767\n",
      "Epoch 41/50\n",
      "126/126 [==============================] - 2s 18ms/step - loss: 0.1606 - accuracy: 0.9076 - val_loss: 0.2686 - val_accuracy: 0.8698\n",
      "Epoch 42/50\n",
      "126/126 [==============================] - 2s 19ms/step - loss: 0.1584 - accuracy: 0.9039 - val_loss: 0.2366 - val_accuracy: 0.8814\n",
      "Epoch 43/50\n",
      "126/126 [==============================] - 2s 19ms/step - loss: 0.1574 - accuracy: 0.9024 - val_loss: 0.2373 - val_accuracy: 0.8767\n",
      "Epoch 44/50\n",
      "126/126 [==============================] - 2s 19ms/step - loss: 0.1537 - accuracy: 0.9066 - val_loss: 0.2250 - val_accuracy: 0.8663\n",
      "Epoch 45/50\n",
      "126/126 [==============================] - 2s 19ms/step - loss: 0.1519 - accuracy: 0.9054 - val_loss: 0.2293 - val_accuracy: 0.8802\n",
      "Epoch 46/50\n",
      "126/126 [==============================] - 2s 19ms/step - loss: 0.1533 - accuracy: 0.9089 - val_loss: 0.2392 - val_accuracy: 0.8779\n",
      "Epoch 47/50\n",
      "126/126 [==============================] - 2s 18ms/step - loss: 0.1519 - accuracy: 0.9054 - val_loss: 0.2709 - val_accuracy: 0.8791\n",
      "Epoch 48/50\n",
      "126/126 [==============================] - 2s 19ms/step - loss: 0.1553 - accuracy: 0.9009 - val_loss: 0.2251 - val_accuracy: 0.8895\n",
      "Epoch 49/50\n",
      "126/126 [==============================] - 2s 18ms/step - loss: 0.1508 - accuracy: 0.9016 - val_loss: 0.3261 - val_accuracy: 0.8558\n",
      "Epoch 50/50\n",
      "126/126 [==============================] - 2s 18ms/step - loss: 0.1503 - accuracy: 0.9084 - val_loss: 0.2289 - val_accuracy: 0.8837\n"
     ]
    }
   ],
   "source": [
    "gas = nne()\n",
    "gas.build_layer(class_len, img_height_resize, img_weight_resize, default_path)\n",
    "gas.train(pre_data.x_train, pre_data.y_train, pre_data.x_val, pre_data.y_val, ephochs_total=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               67109376  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 14)                7182      \n",
      "=================================================================\n",
      "Total params: 67,117,454\n",
      "Trainable params: 67,117,454\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "gas.model_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 5ms/step - loss: 0.2360 - accuracy: 0.8764\n",
      "Test Loss : 0.23604324460029602 | Test Accuracy : 87.64434456825256%\n"
     ]
    }
   ],
   "source": [
    "gas.model_evaluation(pre_data.x_test, pre_data.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        93\n",
      "           1       0.59      0.52      0.55        25\n",
      "           2       1.00      1.00      1.00        70\n",
      "           3       1.00      1.00      1.00        64\n",
      "           4       1.00      1.00      1.00        71\n",
      "           5       0.00      0.00      0.00        77\n",
      "           6       0.50      1.00      0.67        77\n",
      "           7       1.00      1.00      1.00        68\n",
      "           8       0.75      0.92      0.83        26\n",
      "           9       0.80      0.75      0.77        32\n",
      "          10       1.00      1.00      1.00        68\n",
      "          11       1.00      1.00      1.00        73\n",
      "          12       1.00      1.00      1.00        94\n",
      "          13       0.74      0.71      0.73        28\n",
      "\n",
      "    accuracy                           0.88       866\n",
      "   macro avg       0.81      0.85      0.82       866\n",
      "weighted avg       0.83      0.88      0.85       866\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DA4\\anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\DA4\\anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\DA4\\anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "gas.confusion_matrix(pre_data.x_test, pre_data.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_data.prepare_data(img_height_resize, img_weight_resize, flag='predict')\n",
    "\n",
    "prediction_data, prediction_datalist = pre_data.predict_data, pre_data.predict_file_list\n",
    "\n",
    "gas.prediction(prediction_data, prediction_datalist, available_object)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tensor-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "069fac32164d4f8826d0272ba60b2aaaccb33d3d979105e0660a65963367c925"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
