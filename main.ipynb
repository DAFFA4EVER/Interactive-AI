{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[---Saved Object---]\n",
      "0 : Bottle\n",
      "1 : Buds2\n",
      "2 : Daffa\n",
      "3 : Hand\n",
      "4 : Mouse\n",
      "5 : Phone\n"
     ]
    }
   ],
   "source": [
    "from vidcam import VideoCapture\n",
    "import os\n",
    "from preprocessing import object_preprocessing as op\n",
    "from neural_network import neural_network_engine as nne\n",
    "\n",
    "while(True):\n",
    "    flag = input(\"Add new object?(Yes/No) \")\n",
    "    if(flag.lower() == \"no\"):\n",
    "        break\n",
    "    while(flag.lower() != \"yes\"):\n",
    "        flag = input(\"Add new object?(Yes/No) \")\n",
    "\n",
    "    object_name = input(\"Input your object name : \")\n",
    "    VideoCapture.record(object_name)\n",
    "    count_frame = VideoCapture.vid2frame(object_name)\n",
    "\n",
    "    if count_frame < 300:\n",
    "        print(f\"Not enough frame data to process!!! Frame Count : {count_frame} Needed : 300\")\n",
    "        VideoCapture.abandon(object_name)\n",
    "    else:\n",
    "        print(f\"{object_name} has been created!!!\")\n",
    "\n",
    "frame_data = r'D:/Kuliah Telkom University/Python/TCM/Learn/Neural Network/Interactive Test/frame_data'\n",
    "default_path = r'D:/Kuliah Telkom University/Python/TCM/Learn/Neural Network/Interactive Test'\n",
    "available_object = os.listdir(frame_data)\n",
    "print(\"\\n[---Saved Object---]\")\n",
    "for i in range(len(available_object)):\n",
    "    print(f\"{i} : {available_object[i].capitalize()}\")\n",
    "\n",
    "class_len = len(available_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting the data\n",
      "D:/Kuliah Telkom University/Python/TCM/Learn/Neural Network/Interactive Test/frame_data/bottle\n",
      "---------------------------------\n",
      "Object Name :  bottle\n",
      "Object Code :  0\n",
      "Total Images:  425\n",
      "Training :  297\n",
      "Validation :  64\n",
      "Testing :  64\n",
      "D:/Kuliah Telkom University/Python/TCM/Learn/Neural Network/Interactive Test/frame_data/buds2\n",
      "---------------------------------\n",
      "Object Name :  buds2\n",
      "Object Code :  1\n",
      "Total Images:  471\n",
      "Training :  329\n",
      "Validation :  71\n",
      "Testing :  71\n",
      "D:/Kuliah Telkom University/Python/TCM/Learn/Neural Network/Interactive Test/frame_data/daffa\n",
      "---------------------------------\n",
      "Object Name :  daffa\n",
      "Object Code :  2\n",
      "Total Images:  433\n",
      "Training :  303\n",
      "Validation :  65\n",
      "Testing :  65\n",
      "D:/Kuliah Telkom University/Python/TCM/Learn/Neural Network/Interactive Test/frame_data/hand\n",
      "---------------------------------\n",
      "Object Name :  hand\n",
      "Object Code :  3\n",
      "Total Images:  452\n",
      "Training :  316\n",
      "Validation :  68\n",
      "Testing :  68\n",
      "D:/Kuliah Telkom University/Python/TCM/Learn/Neural Network/Interactive Test/frame_data/mouse\n",
      "---------------------------------\n",
      "Object Name :  mouse\n",
      "Object Code :  4\n",
      "Total Images:  447\n",
      "Training :  312\n",
      "Validation :  67\n",
      "Testing :  68\n",
      "D:/Kuliah Telkom University/Python/TCM/Learn/Neural Network/Interactive Test/frame_data/phone\n",
      "---------------------------------\n",
      "Object Name :  phone\n",
      "Object Code :  5\n",
      "Total Images:  623\n",
      "Training :  436\n",
      "Validation :  93\n",
      "Testing :  94\n",
      "---------------------------------\n",
      "Saving split data\n",
      "Save Excel Success\n",
      "Preparing the data\n"
     ]
    }
   ],
   "source": [
    "img_height = 128\n",
    "img_weight = 128\n",
    "\n",
    "pre_data = op(available_object, frame_data, default_path)\n",
    "mode = int(input(\"\\nWhich one do you prefer?\\n1. Use new data\\n2. Load existing data\\nChoose : \"))\n",
    "if(mode==1):\n",
    "    pre_data.split_data()\n",
    "else:\n",
    "    pre_data.load_excel_split()\n",
    "\n",
    "pre_data.prepare_data(img_height, img_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DA4\\anaconda3\\envs\\tensor-gpu\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "63/63 [==============================] - 6s 22ms/step - loss: 1.3334 - accuracy: 0.5068 - val_loss: 1.3253 - val_accuracy: 0.5930\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 0.6487 - accuracy: 0.7948 - val_loss: 1.1520 - val_accuracy: 0.5721\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 1s 18ms/step - loss: 0.4433 - accuracy: 0.8585 - val_loss: 0.2380 - val_accuracy: 0.9488\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 1s 18ms/step - loss: 0.2362 - accuracy: 0.9277 - val_loss: 0.1841 - val_accuracy: 0.9558\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 1s 18ms/step - loss: 0.1619 - accuracy: 0.9478 - val_loss: 0.1112 - val_accuracy: 0.9628\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 1s 18ms/step - loss: 0.1157 - accuracy: 0.9679 - val_loss: 0.0660 - val_accuracy: 0.9837\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 1s 18ms/step - loss: 0.0985 - accuracy: 0.9679 - val_loss: 0.1523 - val_accuracy: 0.9349\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 1s 18ms/step - loss: 0.0857 - accuracy: 0.9789 - val_loss: 0.0922 - val_accuracy: 0.9535\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 1s 18ms/step - loss: 0.0687 - accuracy: 0.9784 - val_loss: 0.1139 - val_accuracy: 0.9395\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 1s 18ms/step - loss: 0.0561 - accuracy: 0.9834 - val_loss: 0.1636 - val_accuracy: 0.9558\n"
     ]
    }
   ],
   "source": [
    "gas = nne(class_len, img_height, img_weight)\n",
    "gas.train(pre_data.x_train, pre_data.y_train, pre_data.x_test, pre_data.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               67109376  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 3078      \n",
      "=================================================================\n",
      "Total params: 67,113,350\n",
      "Trainable params: 67,113,350\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gas.model_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tensor-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "069fac32164d4f8826d0272ba60b2aaaccb33d3d979105e0660a65963367c925"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
